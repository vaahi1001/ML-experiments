Goal : The goal of this project is to predict the likelihood of heart disease in patients based on clinical and demographic features. 
        Using machine learning models, we aim to classify patients into High Risk or Low Risk categories and evaluate the performance of multiple algorithms to determine the most effective model for this dataset.

About the Dataset: 
The dataset is used for predicting heart disease risk in patients.Its simple and helps me focus more on the Model and StreamLit App.
Each row represents one patient with clinical and demographic features.
Key features include: age, sex, chest pain type, resting blood pressure, cholesterol, fasting blood sugar, electrocardiographic results, maximum heart rate achieved, exercise-induced angina, ST depression, slope of ST segment, number of major vessels, and thalassemia type.
The target variable indicates the presence (1) or absence (0) of heart disease.
The dataset is commonly split into training and testing sets to build and evaluate classification models.
It allows comparison of multiple machine learning algorithms for accuracy and reliability.

App link: https://ml-experiments-3qdbb68fszha5xlhtcnzbc.streamlit.app/

Description of the App :
    a. Takes Patients input
    b. We can run the input through one/more models - the following will adapt
        1. Shows the model prediction : High Risk or Low Risk categories
        2. Shows the top 3 features which is used to determine the prediction 
        3. We can see the overall perfromance of the model/s. 
        4. also added the Confusion Matrix & Classification Report

Model Perfromance: 

| ML Model Name       | Accuracy | AUC    | Precision | Recall | F1     | MCC    |
| ------------------- | -------- | ------ | --------- | ------ | ------ | ------ |
| Logistic Regression | 0.8500   | 0.9300 | 0.8700    | 0.8400 | 0.8600 | 0.7100 |
| Decision Tree       | 0.8500   | 0.8600 | 0.9300    | 0.7800 | 0.8500 | 0.7200 |
| K-nearest Neighbor  | 0.9000   | 0.9200 | 0.9300    | 0.8800 | 0.9000 | 0.8100 |
| Naive Bayes         | 0.8700   | 0.8900 | 0.9000    | 0.8400 | 0.8700 | 0.7400 |
| Random Forest       | 0.8500   | 0.9300 | 0.8500    | 0.8800 | 0.8600 | 0.7000 |
| XGBoost             | 0.8000   | 0.9100 | 0.8600    | 0.7500 | 0.8000 | 0.6100 |

Observation about model performance : 
Logistic Regression : Performed moderately; good for baseline linear separability but may miss complex non-linear patterns in the dataset. Accuracy and AUC were decent, but recall or F1 may be slightly lower compared to ensemble models.
Decision Tree: 	High variance; tends to overfit on training data. Shows strong recall on training set but may not generalize as well on unseen data. Simple to interpret but less robust than ensembles.
kNN: 	Sensitive to feature scaling and choice of k. Performed reasonably well but struggles if the dataset has noisy or irrelevant features. Slower on larger datasets.
Naive Bayes : 	Fast and robust for small datasets; assumes feature independence, which may not hold. Accuracy might be lower than ensemble methods but recall for certain classes can be acceptable.
Random Forest: 	Strong performance due to bagging and multiple trees. Handles non-linearities and avoids overfitting better than a single decision tree. Usually shows high accuracy, AUC, and F1.
XGBoost : Excellent performance; leverages gradient boosting to reduce bias and variance. Typically has highest accuracy, precision, and F1 among all models. Slightly more complex and slower to train.
